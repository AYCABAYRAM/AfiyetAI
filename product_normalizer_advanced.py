"""
üéØ ADVANCED PRODUCT NORMALIZER
S√ºrd√ºr√ºlebilir, efektif, 3 katmanlƒ± normalizasyon sistemi

Katman 1: OCR Hata D√ºzeltme
Katman 2: Akƒ±llƒ± Pattern Tanƒ±ma  
Katman 3: Fuzzy Database Matching
"""

import re
import logging
from typing import Optional, Dict, Tuple
from difflib import SequenceMatcher

logger = logging.getLogger(__name__)


class ProductNormalizerAdvanced:
    """Geli≈ümi≈ü √ºr√ºn ismi normalizasyonu"""
    
    def __init__(self):
        # Katman 1: OCR Hata Dictionary
        self.ocr_fixes = {
            # T√ºrk√ße karakter hatalarƒ±
            'I': 'ƒ∞', 'i': 'ƒ±',
            # Sayƒ±-harf karƒ±≈üƒ±mlarƒ±
            '0': 'O', '1': 'I', '5': 'S', '8': 'B',
            # Yaygƒ±n OCR hatalarƒ±
            'STY': 'Sƒ±', 'STYAH': 'Siyah',
            'SUT': 'S√ºt', 'SUTY': 'S√ºt Y',
            'CAY': '√áay', 'CANGA': 'Karamelli',
            'BAR': '', 'FLZ': '',  # Marka √∂n ekleri
        }
        
        # Katman 2: √úr√ºn Pattern Dictionary
        self.product_patterns = {
            # S√ºt √ºr√ºnleri
            r'S[U√úƒ∞I]+T.*?Y?AR[Iƒ∞I]+M.*?YA[Gƒû]+L[Iƒ∞I]+': 'S√ºt Yarƒ±m Yaƒülƒ±',
            r'S[U√úƒ∞I]+T.*?TAM.*?YA[Gƒû]+L[Iƒ∞I]+': 'S√ºt Tam Yaƒülƒ±',
            r'S[U√úƒ∞I]+T': 'S√ºt',
            r'S[U√ú]+ZME.*?PEYN[Iƒ∞I]+R': 'S√ºzme Peynir',
            r'PEYN[Iƒ∞I]+R': 'Peynir',
            
            # Yaƒülar
            r'OMEGA\s*[0-9]*\s*YA[Gƒû][Iƒ∞I]': 'Omega 3 Yaƒüƒ±',
            r'ZEYT[Iƒ∞I]N\s*YA[Gƒû][Iƒ∞I]': 'Zeytinyaƒüƒ±',
            r'AY[C√á][Iƒ∞I]CEK\s*YA[Gƒû][Iƒ∞I]': 'Ay√ßi√ßek Yaƒüƒ±',
            r'YA[Gƒû]': 'Yaƒü',
            
            # √áaylar
            r'S[Iƒ∞I]+Y?AH.*?[C√á]AY': 'Siyah √áay',
            r'YE[S≈û]+[Iƒ∞I]+L.*?[C√á]AY': 'Ye≈üil √áay',
            r'[C√á]AY': '√áay',
            
            # ≈ûekerler
            r'[S≈û]+EKER.*?K[U√ú]+P': 'K√ºp ≈ûeker',
            r'[S≈û]+EKER.*?TOZ': 'Toz ≈ûeker',
            r'[S≈û]+EKER': '≈ûeker',
            
            # Makarnalar
            r'BONCUK\s*MAKARNA': 'Boncuk Makarna',
            r'TEL\s*[S≈û]EHR[Iƒ∞I]YE': 'Tel ≈ûehriye',
            r'ARPA\s*[S≈û]EHR[Iƒ∞ƒ∞]YE': 'Arpa ≈ûehriye',
            r'[S≈û]EHR[Iƒ∞ƒ∞]YE': '≈ûehriye',
            r'MAKARNA': 'Makarna',
            
            # Baharatlar ve diƒüer
            r'PUL\s*B[Iƒ∞I]+BER': 'Pul Biber',
            r'B[Iƒ∞I]+BER': 'Biber',
            r'KEK[Iƒ∞I]+K': 'Kekik',
            r'NANE': 'Nane',
            r'K[Iƒ∞I]+M[Iƒ∞I]+ON': 'Kimyon',
            r'KARAMEL+[Iƒ∞I]+': 'Karamelli Bar',
            
            # Tur≈üu/Konserve
            r'TUR[S≈û]U\s*KAR[Iƒ∞I][S≈û][Iƒ∞I]K': 'Karƒ±≈üƒ±k Tur≈üu',
            r'TUR[S≈û]U': 'Tur≈üu',
            
            # Tohumlar
            r'AY[C√á]+EK[Iƒ∞I]+RDE[Gƒû]+[Iƒ∞I]+': 'Ay√ßekirdeƒüi',
            r'[C√á]+EK[Iƒ∞I]+RDEK': '√áekirdek',
            
            # Yumurta
            r'YUMURTA': 'Yumurta',
            
            # Pirin√ß/Un
            r'P[Iƒ∞I]LAV\s*L[Iƒ∞I]K': 'Pilavlƒ±k Pirin√ß',
            r'P[Iƒ∞I]R[Iƒ∞I]N[C√á]': 'Pirin√ß',
            r'UN': 'Un',
            
            # Tuz
            r'TUZ.*?[YT]+OTLU': 'Otlu Tuz',
            r'TUZ': 'Tuz',
        }
        
        # Katman 3: Bilinen √ºr√ºnler (cache i√ßin)
        self.known_products_cache = {}
        
    def normalize(self, raw_text: str) -> Tuple[str, float]:
        """
        √úr√ºn ismini normalize et
        
        Returns:
            (normalized_name, confidence): Normalize edilmi≈ü isim ve g√ºven skoru (0-1)
        """
        if not raw_text or len(raw_text) < 2:
            return ("√úr√ºn", 0.0)
        
        logger.info(f"üîç NORMALIZE BA≈ûLANGI√á: '{raw_text}'")
        
        # ADIM 1: √ñn temizlik
        text = raw_text.upper().strip()
        
        # ADIM 2: Sayƒ±larƒ± ve birimleri kaldƒ±r
        text = self._remove_numbers_and_units(text)
        
        # ADIM 3: OCR hatalarƒ±nƒ± d√ºzelt
        text = self._fix_ocr_errors(text)
        
        # ADIM 4: Pattern matching yap
        matched_product, confidence = self._match_product_pattern(text)
        
        if confidence > 0.7:
            logger.info(f"‚úÖ PATTERN MATCH: '{raw_text}' ‚Üí '{matched_product}' (g√ºven: {confidence:.2f})")
            return (matched_product, confidence)
        
        # ADIM 5: Fallback - Basit temizlik
        cleaned = self._fallback_clean(text)
        
        logger.info(f"‚ö†Ô∏è FALLBACK: '{raw_text}' ‚Üí '{cleaned}' (g√ºven: 0.5)")
        return (cleaned, 0.5)
    
    def _remove_numbers_and_units(self, text: str) -> str:
        """Sayƒ±larƒ± ve birimleri kaldƒ±r"""
        # T√ºm sayƒ±larƒ± kaldƒ±r
        text = re.sub(r'\d+[.,]?\d*', '', text)
        text = re.sub(r'[IO]\s*\d+', '', text)  # I 08, O8 gibi
        
        # Birimleri kaldƒ±r
        units = r'\b(KG|GR|GRAM|LT|LITRE|ML|ADET|ADT|AD|PCS|PC|G|L|X)\b'
        text = re.sub(units, '', text, flags=re.IGNORECASE)
        
        # √ñzel karakterler
        text = re.sub(r'[%#*¬´¬ª\(\)\[\]{}.,;:!?\-_/\\|]', ' ', text)
        
        # Fazla bo≈üluklar
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def _fix_ocr_errors(self, text: str) -> str:
        """OCR hatalarƒ±nƒ± d√ºzelt - G√ú√áLENDƒ∞Rƒ∞LMƒ∞≈û"""
        # Yaygƒ±n OCR pattern'lerini d√ºzelt (√∂nce bunlar!)
        # "STYAHCAY" -> "Sƒ∞YAH √áAY"
        text = re.sub(r'STY', 'Sƒ∞Y', text)
        text = re.sub(r'SUT', 'S√úT', text)
        text = re.sub(r'CAY', '√áAY', text)
        text = re.sub(r'CANGA', '', text)  # Marka eki
        text = re.sub(r'FLZ', '', text)
        text = re.sub(r'DOGS', '', text)
        text = re.sub(r'KGDOGS', '', text)
        
        # Bilinen hatalarƒ± d√ºzelt
        for wrong, correct in self.ocr_fixes.items():
            text = text.replace(wrong, correct)
        
        return text
    
    def _match_product_pattern(self, text: str) -> Tuple[str, float]:
        """Pattern matching ile √ºr√ºn tanƒ±"""
        best_match = None
        best_confidence = 0.0
        
        for pattern, product_name in self.product_patterns.items():
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                # E≈üle≈üme kalitesini hesapla
                match_ratio = len(match.group(0)) / len(text)
                confidence = min(0.95, match_ratio * 1.2)  # Max 0.95
                
                if confidence > best_confidence:
                    best_match = product_name
                    best_confidence = confidence
        
        if best_match:
            return (best_match, best_confidence)
        
        return ("", 0.0)
    
    def _fallback_clean(self, text: str) -> str:
        """Fallback temizlik - hi√ßbir pattern e≈üle≈ümezse"""
        # √áok kƒ±sa kelimeleri kaldƒ±r
        words = text.split()
        words = [w for w in words if len(w) > 2]
        
        if not words:
            return "√úr√ºn"
        
        # Title case yap
        cleaned = ' '.join(words).title()
        
        # T√ºrk√ße karakter d√ºzeltmeleri
        cleaned = cleaned.replace('I', 'ƒ±').replace('ƒ∞', 'i')
        
        return cleaned if len(cleaned) >= 3 else "√úr√ºn"
    
    def fuzzy_match_database(self, text: str, db_products: list) -> Optional[str]:
        """
        Veritabanƒ±ndaki √ºr√ºnlerle fuzzy matching yap
        
        Args:
            text: Normalize edilmi≈ü metin
            db_products: [(product_id, product_name), ...] listesi
        
        Returns:
            En iyi e≈üle≈üen √ºr√ºn adƒ± veya None
        """
        if not db_products:
            return None
        
        best_match = None
        best_ratio = 0.0
        
        for prod_id, prod_name in db_products:
            ratio = SequenceMatcher(None, text.upper(), prod_name.upper()).ratio()
            
            if ratio > best_ratio and ratio > 0.75:  # %75+ benzerlik
                best_match = prod_name
                best_ratio = ratio
        
        if best_match:
            logger.info(f"üéØ FUZZY MATCH: '{text}' ‚Üí '{best_match}' (benzerlik: {best_ratio:.2f})")
            return best_match
        
        return None


# Global instance
_normalizer = ProductNormalizerAdvanced()


def normalize_product_name(raw_text: str, db_products: list = None) -> Tuple[str, float]:
    """
    √úr√ºn ismini normalize et (wrapper function)
    
    Args:
        raw_text: Ham OCR metni
        db_products: Opsiyonel veritabanƒ± √ºr√ºnleri listesi
    
    Returns:
        (normalized_name, confidence)
    """
    # Temel normalizasyon
    name, confidence = _normalizer.normalize(raw_text)
    
    # Eƒüer g√ºven d√º≈ü√ºkse ve db varsa, fuzzy match dene
    if confidence < 0.8 and db_products:
        fuzzy_match = _normalizer.fuzzy_match_database(name, db_products)
        if fuzzy_match:
            return (fuzzy_match, 0.9)
    
    return (name, confidence)

